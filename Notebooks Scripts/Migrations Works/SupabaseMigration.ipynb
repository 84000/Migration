{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-01T10:29:36.593518Z",
     "start_time": "2024-08-01T10:29:36.549042Z"
    }
   },
   "source": [
    "from supabase import create_client,Client\n",
    "import os\n",
    "# get environment variables from .env file\n",
    "import os\n",
    "\n",
    "def load_env():\n",
    "    with open('.env', 'r') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                key, value = line.strip().split('=', 1)\n",
    "                os.environ[key] = value\n",
    "\n",
    "load_env()\n",
    "\n",
    "\n",
    "# get environment variables\n",
    "url: str = os.getenv(\"SUPABASE_URL\")\n",
    "key: str = os.getenv(\"SUPABASE_KEY\")\n",
    "supabase = create_client(url, key)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "# functions to load data\n",
    "import json\n",
    "import requests\n",
    "\n",
    "def get_translations(count):\n",
    "    url = 'https://read.84000-translate.org/translations.json?api-version=0.4.0'\n",
    "    response = requests.get(url)\n",
    "    works = json.loads(response.text)\n",
    "    # only return the required number of translations\n",
    "    print (f\"Processing {count}of {len(works['work'])} translations\")\n",
    "    return works['work'][:count]\n",
    "\n",
    "def get_work(Work_id):\n",
    "    link = f\"../../data-json/{Work_id}.json\"\n",
    "    print(\"loading file\",link)\n",
    "    # fet the json data from the local file\n",
    "    with open(link, 'r') as file:\n",
    "        work = json.loads(file.read())\n",
    "    return work\n",
    "\n",
    "def make_title(work,WorkId):\n",
    "    titles = work['work'][0]['title']\n",
    "    titles_dicts = [dict({'work_uuid': WorkId,\n",
    "                          'type': title['titleType'],\n",
    "                          'content': title['content'],\n",
    "                          'language': title['language'],\n",
    "                          'migrationId': title['titleMigrationId']}) for title in titles]\n",
    "    return titles_dicts\n",
    "\n",
    "def make_passages(work,WorkId):\n",
    "    # check if work has translation\n",
    "    if 'translation' not in work:\n",
    "        return None\n",
    "    passages = work['translation']['passage']\n",
    "    passage_dict = [dict({'work_uuid': WorkId,\n",
    "                          'xmlId': passage['xmlId'],\n",
    "                          'parent': passage['parentId'],\n",
    "                          'label': passage['passageLabel'],\n",
    "                          'type': passage['segmentationType'],\n",
    "                          'sort': passage['passageSort'],\n",
    "                          'content': passage['content']}) for passage in passages]\n",
    "    return passage_dict\n",
    "\n",
    "def make_work(translation,work):\n",
    "    title = translation['work'][0]['title'][0]['content']\n",
    "    Current_Work = translation['work'][0]\n",
    "\n",
    "    work_dict = dict({'xmlId': Current_Work['workId'],\n",
    "                      'url': Current_Work['url'],\n",
    "                      'type': Current_Work['workType'],\n",
    "                      'toh': work['catalogueWorkIds'],\n",
    "                      'publicationDate': translation['publicationDate'],\n",
    "                      'publicationStatus': translation['publicationStatus'],\n",
    "                      'publicationVersion': translation['publicationVersion'],\n",
    "                      'title': title,\n",
    "                      'migrationJson': translation})\n",
    "    return work_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-01T10:55:38.877074Z",
     "start_time": "2024-08-01T10:55:38.865722Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T10:54:45.224064Z",
     "start_time": "2024-08-01T10:54:43.003706Z"
    }
   },
   "cell_type": "code",
   "source": "print(get_translations(1))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1of 4297 translations\n",
      "[{'workId': 'UT22084-001-001', 'workType': 'eft:translation', 'url': '/translation/UT22084-001-001.json?api-version=0.4.0&annotate=true', 'htmlUrl': 'https://read.84000.co/translation/UT22084-001-001.html', 'catalogueWorkIds': 'toh1-1'}]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T10:29:42.878379Z",
     "start_time": "2024-08-01T10:29:42.867935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# upsert into supabase\n",
    "def store_work(work_dict):\n",
    "    # check if the work already exists with the same xmlId\n",
    "    # if exists return the workId\n",
    "    # else insert the work and return the workId\n",
    "    does = supabase.table('works').select('uuid').eq('xmlId',work_dict['xmlId']).execute()\n",
    "    if (len(does.data)!=0):\n",
    "        print(\"‚ö†Ô∏è Work Already Exists, Delete Work and its Titles and Passages\")\n",
    "        # delete the work and all its titles and passages\n",
    "        data_temp,count_temp = supabase.table('works').delete().eq('uuid',does.data[0]['uuid']).execute()\n",
    "    try:\n",
    "        work_data,count = supabase.table('works').insert(work_dict).execute()\n",
    "        return work_data[1][0]['uuid']\n",
    "    except Exception as e:\n",
    "        print (\"Error Occured\",e)\n",
    "        return None\n",
    "    \n",
    "    \n",
    "def store_titles(titles_dicts):\n",
    "    # check if titles already exists with the same migrationId\n",
    "    try:\n",
    "        title_data,count = supabase.table('titles').upsert(titles_dicts).execute()\n",
    "        print(\"‚úÖ Added titles\",len(title_data[1]))\n",
    "        return \"success\"\n",
    "    except Exception as e:\n",
    "        print(\"Error Occured\",e)\n",
    "        return e\n",
    "        # If error occurs delete all just inserted data\n",
    "        # try:\n",
    "        #     if (title_data[1]):\n",
    "        #         for inserts in title_data[1]:\n",
    "        #             print(inserts)\n",
    "        #             data_temp,count_temp = supabase.table('titles').delete().eq('id',inserts['id']).execute()\n",
    "        #             print('deleted',data_temp[1])\n",
    "        # except IndexError:\n",
    "        #     print(\"No Data to Delete\")\n",
    "            \n",
    "def store_passages(passage_dict):\n",
    "    try:\n",
    "        passage_data,count = supabase.table('passages').upsert(passage_dict).execute()\n",
    "        print(\"‚úÖ Added passages\",len(passage_data[1]))\n",
    "        return \"success\"\n",
    "    except Exception as e:\n",
    "        print(\"Error Occured\",e)\n",
    "        return e\n",
    "        # If error occurs delete all just inserted data\n",
    "        # try:\n",
    "        #     if (passage_data[1]):\n",
    "        #         for inserts in passage_data[1]:\n",
    "        #             print(inserts)\n",
    "        #             data_temp,count_temp = supabase.table('passages').delete().eq('id',inserts['id']).execute()\n",
    "        #             print('deleted',data_temp[1])\n",
    "        # except IndexError:\n",
    "        #     print(\"No Data to Delete\")\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T10:29:47.890656Z",
     "start_time": "2024-08-01T10:29:47.819563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T18:30:02.264067Z",
     "start_time": "2024-06-10T18:30:02.247107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Simple Excuter ( Single Thread )\n",
    "# 1. get required  number of translations\n",
    "# 2. Load the data into Supabase and get back the workId\n",
    "# 3. Get the work data from the local file\n",
    "# 4. Get the titles and passages\n",
    "# 5. Create Title and passage dictionary with WorkId\n",
    "\n",
    "def load_data(translation_count):\n",
    "    f = IntProgress(min=0, max=translation_count) # instantiate the bar\n",
    "    f.description = \"Progress\"\n",
    "    f.bar_style = \"info\"\n",
    "    display(f) # display the bar\n",
    "    works = get_translations(translation_count)\n",
    "    count = 0\n",
    "    for work in works:\n",
    "        try:\n",
    "            work_uuid = None\n",
    "            WorkId = work['workId']\n",
    "            print(\"üîÅ Processing current:\",WorkId,\"entry\",count+1,\"of\",len(works))\n",
    "            translation = get_work(WorkId)\n",
    "            work_dict = make_work(work,translation)\n",
    "            print(\"‚òÅÔ∏è Storing Work\")\n",
    "            work_uuid = store_work(work_dict)\n",
    "            if (work_uuid != None):\n",
    "                print(\"Work UUID\",work_uuid)\n",
    "                print(\"Loading Titles\")\n",
    "                titles_dicts = make_title(translation,work_uuid)\n",
    "                print(\"Loading Passages\")\n",
    "                passage_dict = make_passages(translation,work_uuid)\n",
    "                print(\"‚òÅÔ∏è Storing Title\")\n",
    "                return_titles = store_titles(titles_dicts)\n",
    "                if (return_titles != \"success\"):\n",
    "                    raise Exception(return_titles)\n",
    "                if (passage_dict):\n",
    "                    print(\"Storing Passages\")\n",
    "                    return_passages = store_passages(passage_dict)\n",
    "                    if (return_passages != \"success\"):\n",
    "                        raise Exception(return_passages)\n",
    "                else:\n",
    "                    print(\"‚ùå No Passages to Store\")\n",
    "            count += 1\n",
    "        except Exception as e:\n",
    "            #delete work cascade\n",
    "            try:\n",
    "                print('‚ÄºÔ∏è error in',WorkId)\n",
    "                # store error as string\n",
    "                supabase.table('Error').upsert({'error':str(e),'xmlId':WorkId}).execute()\n",
    "                if (work_uuid):\n",
    "                    data_temp,count_temp = supabase.table('works').delete().eq('uuid',work_uuid).execute()\n",
    "                    print('deleted',work_uuid)\n",
    "            except IndexError:\n",
    "                print(\"No Data to Delete\")\n",
    "        f.value += 1 # signal to increment the progress bar    \n",
    "    # show a progress bar of the works loaded\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"‚úÖ Done\",count,\"works loaded\")\n",
    "    \n",
    "    return\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T10:55:59.379296Z",
     "start_time": "2024-08-01T10:55:59.361780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Multi Threaded Executor\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "from ipywidgets import IntProgress, Output\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Define the function to process each work\n",
    "def process_work(work, status_output, f):\n",
    "    work_uuid = None\n",
    "    WorkId = work['workId']\n",
    "    try:\n",
    "        status_output.append_stdout(f\"üîÅ Processing current: {WorkId} entry\\n\")\n",
    "        translation = get_work(WorkId)\n",
    "        work_dict = make_work(translation,work)\n",
    "        status_output.append_stdout(\"‚òÅÔ∏è Storing Work\\n\")\n",
    "        work_uuid = store_work(work_dict)\n",
    "        if work_uuid:\n",
    "            status_output.append_stdout(f\"Work UUID {work_uuid}\\n\")\n",
    "            status_output.append_stdout(\"Loading Titles\\n\")\n",
    "            titles_dicts = make_title(translation, work_uuid)\n",
    "            status_output.append_stdout(\"Loading Passages\\n\")\n",
    "            passage_dict = make_passages(translation, work_uuid)\n",
    "            status_output.append_stdout(\"‚òÅÔ∏è Storing Title\\n\")\n",
    "            return_titles = store_titles(titles_dicts)\n",
    "            if return_titles != \"success\":\n",
    "                raise Exception(return_titles)\n",
    "            if passage_dict:\n",
    "                status_output.append_stdout(\"Storing Passages\\n\")\n",
    "                return_passages = store_passages(passage_dict)\n",
    "                if return_passages != \"success\":\n",
    "                    raise Exception(return_passages)\n",
    "            else:\n",
    "                status_output.append_stdout(\"‚ùå No Passages to Store\\n\")\n",
    "        f.value += 1  # Update the global progress bar\n",
    "    except Exception as e:\n",
    "        # Handle the error\n",
    "        try:\n",
    "            status_output.append_stdout(f'‚ÄºÔ∏è error in {WorkId}\\n')\n",
    "            # Store error as string\n",
    "            supabase.table('Error').upsert({'error': str(e), 'xmlId': WorkId}).execute()\n",
    "            if work_uuid:\n",
    "                data_temp, count_temp = supabase.table('works').delete().eq('uuid', work_uuid).execute()\n",
    "                status_output.append_stdout(f'deleted {work_uuid}\\n')\n",
    "        except IndexError:\n",
    "            status_output.append_stdout(\"No Data to Delete\\n\")\n",
    "    return\n",
    "\n",
    "def load_data(translation_count):\n",
    "    works = get_translations(translation_count)\n",
    "\n",
    "    f = IntProgress(min=0, max=translation_count)  # instantiate the global progress bar\n",
    "    f.description = \"Progress\"\n",
    "    f.bar_style = \"info\"\n",
    "    display(f)  # display the global progress bar\n",
    "\n",
    "    status_output = Output()\n",
    "    display(status_output)\n",
    "\n",
    "    # Use ThreadPoolExecutor to run process_work in parallel with a maximum of 10 workers\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        futures = [executor.submit(process_work, work, status_output, f) for work in works]\n",
    "        concurrent.futures.wait(futures)\n",
    "\n",
    "    status_output.append_stdout(f\"‚úÖ Done {len(works)} works loaded\\n\")\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T10:56:12.768351Z",
     "start_time": "2024-08-01T10:56:01.474909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "translation_count = 1  # or any number you need\n",
    "load_data(translation_count)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1of 4297 translations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IntProgress(value=0, bar_style='info', description='Progress', max=1)"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6504c2744a47424ebea59200fa217330"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8d9f3c7c65c547518687b70541fdba6f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file ../../data-json/UT22084-001-001.json\n",
      "‚ö†Ô∏è Work Already Exists, Delete Work and its Titles and Passages\n",
      "‚úÖ Added titles 11\n",
      "‚úÖ Added passages 1421\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
